# H∆Ø·ªöNG D·∫™N CH·∫†Y TR√äN M√ÅY LOCAL

## üéØ T·∫°i sao ch·∫°y local?
- Codespace **timeout** khi x·ª≠ l√Ω dataset l·ªõn (230M rows)
- CPU local **kh√¥ng gi·ªõi h·∫°n th·ªùi gian** ch·∫°y
- Tr√°nh b·ªã kill process (Signal 143)

---

## üì• B∆Ø·ªöC 1: Clone/Download Code

### Option A: Clone t·ª´ GitHub
```bash
git clone https://github.com/quang25808600233-max/cnn---tfm.git
cd cnn---tfm
```

### Option B: Download ZIP
1. V√†o GitHub repo: https://github.com/quang25808600233-max/cnn---tfm
2. Click **Code** ‚Üí **Download ZIP**
3. Gi·∫£i n√©n v√†o th∆∞ m·ª•c l√†m vi·ªác

---

## üêç B∆Ø·ªöC 2: Setup Python Environment

### Y√™u c·∫ßu:
- **Python 3.10+** (khuy·∫øn ngh·ªã 3.12)
- **16GB RAM** tr·ªü l√™n (32GB t·ªëi ∆∞u)
- **50GB disk** tr·ªëng cho chunks

### C√†i ƒë·∫∑t dependencies:

```bash
# T·∫°o virtual environment
python -m venv .venv

# K√≠ch ho·∫°t (Windows)
.venv\Scripts\activate

# K√≠ch ho·∫°t (macOS/Linux)
source .venv/bin/activate

# C√†i packages
pip install -r requirements.txt
```

**File `requirements.txt` ƒë√£ c√≥ s·∫µn:**
```
numpy>=1.24.0
pandas>=2.0.0
pyarrow>=5.0.0
tensorflow>=2.20.0
scikit-learn>=1.3.0
```

---

## üì¶ B∆Ø·ªöC 3: Chu·∫©n b·ªã Data

### Copy file XAUUSD.parquet v√†o th∆∞ m·ª•c g·ªëc:

**Windows:**
```bash
copy "C:\Users\Dinh Vuong Ng\Desktop\XAUUSD.parquet" .
```

**macOS/Linux:**
```bash
cp ~/Desktop/XAUUSD.parquet .
```

### Ki·ªÉm tra file:
```bash
ls -lh XAUUSD.parquet
# Ph·∫£i th·∫•y: ~2.3GB, 230M rows
```

---

## üöÄ B∆Ø·ªöC 4: Ch·∫°y Chunking

### Full dataset (230M rows ‚Üí ~460 chunks):

```bash
python xauusd_chunking_local.py
```

**Th·ªùi gian ∆∞·ªõc t√≠nh:**
- **CPU Intel i5/i7**: 6-12 gi·ªù
- **CPU AMD Ryzen 5/7**: 5-10 gi·ªù
- **Apple M1/M2**: 4-8 gi·ªù

**K·∫øt qu·∫£:**
- Th∆∞ m·ª•c `XAUUSD_Chunks/` v·ªõi ~460 files `.npz`
- M·ªói chunk ~26MB, t·ªïng ~12GB
- File `manifest.json` ch·ª©a metadata

### Test v·ªõi 1 row group (nhanh):
```bash
# S·ª≠a trong xauusd_chunking_local.py:
# 'max_row_groups': 1

python xauusd_chunking_local.py
```

---

## üß† B∆Ø·ªöC 5: Train Model

```bash
python train_model.py
```

**Train settings:**
- **Batch size**: 512 (gi·∫£m xu·ªëng 256 n·∫øu thi·∫øu RAM)
- **Epochs**: 50 (early stopping enabled)
- **Validation split**: 20%

**Outputs:**
- `best_model.keras` - Model t·ªët nh·∫•t
- `training_history.json` - Metrics theo epoch

---

## ‚öôÔ∏è T√πy ch·ªânh CONFIG

### xauusd_chunking_local.py:

```python
CONFIG = {
    'chunk_rows': 20000,      # TƒÉng l√™n 50000 n·∫øu RAM nhi·ªÅu
    'sequence_length': 60,    # ƒê·ªô d√†i sequence
    'score_threshold': 1.5,   # Threshold labeling
    'max_row_groups': None,   # None = full dataset
}
```

### train_model.py:

```python
BATCH_SIZE = 512       # Gi·∫£m xu·ªëng 256 n·∫øu OOM
MAX_CHUNKS = None      # None = train all chunks
EPOCHS = 50
```

---

## üîç Monitor Progress

### Trong terminal kh√°c:

**Windows (PowerShell):**
```powershell
Get-Content XAUUSD_Chunks\manifest.json
dir XAUUSD_Chunks\*.npz | Measure-Object
```

**macOS/Linux:**
```bash
watch -n 5 'ls -1 XAUUSD_Chunks/*.npz | wc -l'
tail -f chunking.log  # N·∫øu redirect output
```

---

## ‚ùå Troubleshooting

### 1. **ImportError: numpy kh√¥ng t√¨m th·∫•y**
```bash
pip install --upgrade pip
pip install -r requirements.txt
```

### 2. **MemoryError khi chunking**
- Gi·∫£m `chunk_rows` xu·ªëng 10000-15000
- Close c√°c app kh√°c ƒë·ªÉ free RAM

### 3. **Training b·ªã OOM**
- Gi·∫£m `BATCH_SIZE` t·ª´ 512 ‚Üí 256 ‚Üí 128
- Set `MAX_CHUNKS = 100` ƒë·ªÉ train subset

### 4. **File XAUUSD.parquet kh√¥ng t√¨m th·∫•y**
```bash
# Ki·ªÉm tra ƒë∆∞·ªùng d·∫´n
ls -la XAUUSD.parquet

# N·∫øu ·ªü folder kh√°c, s·ª≠a CONFIG:
'parquet_path': '/full/path/to/XAUUSD.parquet'
```

---

## üìä Ki·ªÉm tra k·∫øt qu·∫£

### Sau khi chunking:
```python
# check_chunks.py
import numpy as np
import os

chunks = sorted([f for f in os.listdir('XAUUSD_Chunks') if f.endswith('.npz')])
print(f"Total chunks: {len(chunks)}")

# Load 1 chunk ƒë·ªÉ test
data = np.load(f'XAUUSD_Chunks/{chunks[0]}')
print(f"X shape: {data['X'].shape}")
print(f"y shape: {data['y'].shape}")
print(f"Label distribution: {np.bincount(data['y'])}")
```

### Sau khi training:
```python
# test_model.py
from tensorflow import keras
import numpy as np

model = keras.models.load_model('best_model.keras')
print(model.summary())

# Test predict
data = np.load('XAUUSD_Chunks/chunk_0000.npz')
X_test = data['X'][:100]
preds = model.predict(X_test)
print(f"Predictions: {preds[:5]}")
```

---

## üí° Tips t·ªëi ∆∞u

1. **Run overnight** - ƒê·ªÉ m√°y ch·∫°y qua ƒë√™m
2. **Disable sleep** - T·∫Øt ch·∫ø ƒë·ªô ng·ªß trong settings
3. **Close apps** - ƒê√≥ng Chrome, VSCode ƒë·ªÉ free RAM
4. **SSD preferred** - Ch·∫°y tr√™n SSD nhanh h∆°n HDD
5. **Monitor temperature** - Ki·ªÉm tra nhi·ªát ƒë·ªô CPU (d√πng HWMonitor)

---

## üìû Support

N·∫øu g·∫∑p l·ªói:
1. Check terminal output
2. Ki·ªÉm tra file `manifest.json` ƒë√£ t·∫°o ch∆∞a
3. Xem log errors trong Python traceback
4. GitHub Issues: https://github.com/quang25808600233-max/cnn---tfm/issues

---

**‚úÖ S·∫µn s√†ng ch·∫°y full dataset tr√™n m√°y local!**
